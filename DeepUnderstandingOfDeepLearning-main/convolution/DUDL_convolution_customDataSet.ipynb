{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1GRajDS-VF5z8IslzZuMqbis3X6HDD-Uo",
     "timestamp": 1619968661706
    },
    {
     "file_id": "1m0n2-UmB2tJiIDadlFkE6L5A4iZSqeBf",
     "timestamp": 1619459134813
    },
    {
     "file_id": "19G9gTeBlYPQ-s3VS_3K2bVFtKTP344j6",
     "timestamp": 1619444797767
    },
    {
     "file_id": "1FcEBC0NAESIlHQkv6_85R-XDUKGE8XbM",
     "timestamp": 1619155961717
    },
    {
     "file_id": "1qKgZ8kVcqNgwtBzHbWq5yJH_HqI6DxWW",
     "timestamp": 1617803880910
    },
    {
     "file_id": "15cpyHkJ435B4MqbyGjAH1poN4nCy_DE4",
     "timestamp": 1617737766196
    },
    {
     "file_id": "1OLuWuaFu0hcFgkQ2hh5BqbRuqUZD7XcQ",
     "timestamp": 1617734878578
    },
    {
     "file_id": "1XvzVGJPTJifVh8OpZVB7ykLxyUqYwQ1j",
     "timestamp": 1617196833019
    },
    {
     "file_id": "1bv1_y32e3KEExFKKlPfC3rpw1JxmBr8H",
     "timestamp": 1617124341706
    },
    {
     "file_id": "1GMq8u7KyHB2AE7Teyls9gK1T01OduQSn",
     "timestamp": 1616697516760
    },
    {
     "file_id": "1Ui3kyHim-e0XLgDs2mkBxVlYg7TKYtcg",
     "timestamp": 1616615469755
    },
    {
     "file_id": "1YpHocGI4rApOxIBb1ZghCU5L-hFnv4CK",
     "timestamp": 1616608248670
    }
   ],
   "authorship_tag": "ABX9TyPbD7UUlxPnb4BI+hE9YoGH"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhWV8oes-wKR"
   },
   "source": [
    "# COURSE: A deep understanding of deep learning\n",
    "## SECTION: Convolution and transformations\n",
    "### LECTURE: Creating and using custom DataSets\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com\n",
    "##### COURSE URL: udemy.com/course/deeplearning_x/?couponCode=202401"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6fD1Q1CK35Pv"
   },
   "source": [
    "# FYI, review paper on data augmentation in DL:\n",
    "# https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0197-0"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YeuAheYyhdZw",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683207517121,
     "user_tz": -180,
     "elapsed": 9249,
     "user": {
      "displayName": "Mike X Cohen",
      "userId": "13901636194183843661"
     }
    },
    "outputId": "a81a4882-8734-4ad4-908c-731e4d818e44"
   },
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# import transformations and dataset/loader\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-1-9bb796999ba6>:12: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  display.set_matplotlib_formats('svg')\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HOkOefftqyg"
   },
   "source": [
    "# Import the data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VhIKo0_iaGz2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683208240214,
     "user_tz": -180,
     "elapsed": 5489,
     "user": {
      "displayName": "Mike X Cohen",
      "userId": "13901636194183843661"
     }
    },
    "outputId": "4f06a277-794e-4e8b-a202-1fad1b0dd171"
   },
   "source": [
    "# import dataset (comes with colab!)\n",
    "data = np.loadtxt(open('sample_data/mnist_train_small.csv','rb'),delimiter=',')\n",
    "\n",
    "# extract only the first 8\n",
    "labels = data[:8,0]\n",
    "data   = data[:8,1:]\n",
    "\n",
    "# normalize the data to a range of [0 1]\n",
    "dataNorm = data / np.max(data)\n",
    "\n",
    "# reshape to 2D!\n",
    "dataNorm = dataNorm.reshape(dataNorm.shape[0],1,28,28)\n",
    "\n",
    "# check sizes\n",
    "print(dataNorm.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "# convert to torch tensor format\n",
    "dataT   = torch.tensor( dataNorm ).float()\n",
    "labelsT = torch.tensor( labels ).long()"
   ],
   "execution_count": 45,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(8, 1, 28, 28)\n",
      "(8,)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-vy8Pbj4Rg1"
   },
   "source": [
    "# Create a new class to create our custom dataset type"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6VcIE1DExDvV"
   },
   "source": [
    "# My custom dataset class is modeled after the official class\n",
    "??torch.utils.data.TensorDataset"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aDl-yEbpvg2I",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683207538686,
     "user_tz": -180,
     "elapsed": 271,
     "user": {
      "displayName": "Mike X Cohen",
      "userId": "13901636194183843661"
     }
    }
   },
   "source": [
    "class customDataset(Dataset):\n",
    "  def __init__(self, tensors, transform=None):\n",
    "\n",
    "    # check that sizes of data and labels match\n",
    "    assert all(tensors[0].size(0)==t.size(0) for t in tensors), \"Size mismatch between tensors\"\n",
    "    \n",
    "    # assign inputs\n",
    "    self.tensors   = tensors\n",
    "    self.transform = transform\n",
    "\n",
    "  # what to do when someone wants and item from the dataset\n",
    "  def __getitem__(self, index): \n",
    "\n",
    "    # return transformed version of x if there are transforms\n",
    "    if self.transform:\n",
    "      x = self.transform(self.tensors[0][index])\n",
    "    else:\n",
    "      x = self.tensors[0][index]\n",
    "\n",
    "    # and return label\n",
    "    y = self.tensors[1][index]\n",
    "\n",
    "    return x,y # return the (data,label) tuple\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.tensors[0].size(0)"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eq1WEKwl4ew9"
   },
   "source": [
    "# data -> dataset -> dataloader"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NP5mv3Khr0Eh",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683207542733,
     "user_tz": -180,
     "elapsed": 365,
     "user": {
      "displayName": "Mike X Cohen",
      "userId": "13901636194183843661"
     }
    }
   },
   "source": [
    "# Note: several transforms work only on PIL-format data, so it's common to transform\n",
    "#       to PIL, apply transformations, then transform back to tensor.\n",
    "\n",
    "# create a list of transforms to apply to the image\n",
    "imgtrans = T.Compose([ \n",
    "                      T.ToPILImage(),\n",
    "                      T.RandomVerticalFlip(p=.5),\n",
    "                      # T.RandomRotation(90), \n",
    "                      T.ToTensor()\n",
    "                       ])"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xlYbyhTgxMt3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683208240445,
     "user_tz": -180,
     "elapsed": 4,
     "user": {
      "displayName": "Mike X Cohen",
      "userId": "13901636194183843661"
     }
    }
   },
   "source": [
    "# now convert the data into datasets and then dataloaders\n",
    "\n",
    "# convert into PyTorch Datasets\n",
    "# NOTE: we have no test data here, but you should apply the same transformations to the test data\n",
    "train_data = customDataset((dataT,labelsT),imgtrans)\n",
    "\n",
    "# translate into dataloader objects\n",
    "dataLoaded = DataLoader(train_data,batch_size=8,shuffle=False)"
   ],
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oHAqShzs9-or"
   },
   "source": [
    "type(train_data)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u__Nn2BG4u3d"
   },
   "source": [
    "# Let's see the effects!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2AjYQPw2wuNl"
   },
   "source": [
    "# import data from the dataloader, just like during training\n",
    "X,y = next(iter(dataLoaded))\n",
    "\n",
    "\n",
    "# create a figure\n",
    "fig,axs = plt.subplots(2,8,figsize=(16,4))\n",
    "\n",
    "\n",
    "# loop over images in the dataset\n",
    "for i in range(8):\n",
    "\n",
    "  # draw images\n",
    "  axs[0,i].imshow(dataT[i,0,:,:].detach(),cmap='gray')\n",
    "  axs[1,i].imshow(X[i,0,:,:].detach(),cmap='gray')\n",
    "\n",
    "  # some niceties\n",
    "  for row in range(2):\n",
    "    axs[row,i].set_xticks([])\n",
    "    axs[row,i].set_yticks([])\n",
    "\n",
    "# row labels\n",
    "axs[0,0].set_ylabel('Original')\n",
    "axs[1,0].set_ylabel('torch dataset')\n",
    "\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bwBwIb1yynNB"
   },
   "source": [
    "# Important to know: we haven't actually increased the amount of data\n",
    "len(train_data)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dimcax6w0vvY"
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  }
 ]
}