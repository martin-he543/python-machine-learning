{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "DUDL_convolution_codeChallenge.ipynb",
   "provenance": [
    {
     "file_id": "19imE5cZVTySOpFOe4Uvw97qMPMgs0MJ2",
     "timestamp": 1619520513379
    },
    {
     "file_id": "1GRajDS-VF5z8IslzZuMqbis3X6HDD-Uo",
     "timestamp": 1619468278654
    },
    {
     "file_id": "1m0n2-UmB2tJiIDadlFkE6L5A4iZSqeBf",
     "timestamp": 1619459134813
    },
    {
     "file_id": "19G9gTeBlYPQ-s3VS_3K2bVFtKTP344j6",
     "timestamp": 1619444797767
    },
    {
     "file_id": "1FcEBC0NAESIlHQkv6_85R-XDUKGE8XbM",
     "timestamp": 1619155961717
    },
    {
     "file_id": "1qKgZ8kVcqNgwtBzHbWq5yJH_HqI6DxWW",
     "timestamp": 1617803880910
    },
    {
     "file_id": "15cpyHkJ435B4MqbyGjAH1poN4nCy_DE4",
     "timestamp": 1617737766196
    },
    {
     "file_id": "1OLuWuaFu0hcFgkQ2hh5BqbRuqUZD7XcQ",
     "timestamp": 1617734878578
    },
    {
     "file_id": "1XvzVGJPTJifVh8OpZVB7ykLxyUqYwQ1j",
     "timestamp": 1617196833019
    },
    {
     "file_id": "1bv1_y32e3KEExFKKlPfC3rpw1JxmBr8H",
     "timestamp": 1617124341706
    },
    {
     "file_id": "1GMq8u7KyHB2AE7Teyls9gK1T01OduQSn",
     "timestamp": 1616697516760
    },
    {
     "file_id": "1Ui3kyHim-e0XLgDs2mkBxVlYg7TKYtcg",
     "timestamp": 1616615469755
    },
    {
     "file_id": "1YpHocGI4rApOxIBb1ZghCU5L-hFnv4CK",
     "timestamp": 1616608248670
    }
   ],
   "collapsed_sections": [
    "mb0fBtyfEpsj"
   ],
   "authorship_tag": "ABX9TyPOt/RlHgcfJ0cx2nA7NDMT"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhWV8oes-wKR"
   },
   "source": [
    "# COURSE: A deep understanding of deep learning\n",
    "## SECTION: Convolution and transformations\n",
    "### LECTURE: CodeChallenge: choose the parameters\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com\n",
    "##### COURSE URL: udemy.com/course/deeplearning_x/?couponCode=202401"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YeuAheYyhdZw",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1625124891642,
     "user_tz": -120,
     "elapsed": 2442,
     "user": {
      "displayName": "Mike X Cohen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjXSur8ulydyiQQEh2U6pYGIhDN22fqYYNNDg49A=s64",
      "userId": "13901636194183843661"
     }
    }
   },
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HOkOefftqyg"
   },
   "source": [
    "# Sample problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EiLI77Lh9yms"
   },
   "source": [
    "### Convolve an image of size 1x256x256 to produce a 1x252x84 result"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VhIKo0_iaGz2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1625124892032,
     "user_tz": -120,
     "elapsed": 6,
     "user": {
      "displayName": "Mike X Cohen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjXSur8ulydyiQQEh2U6pYGIhDN22fqYYNNDg49A=s64",
      "userId": "13901636194183843661"
     }
    },
    "outputId": "39ac054e-2456-47e3-87cf-6381014e3808"
   },
   "source": [
    "# parameters\n",
    "inChans  = 1 # RGB\n",
    "imsize   = [256,256]\n",
    "outChans = 1\n",
    "krnSize  = 7 # should be an odd number\n",
    "stride   = (1,3)\n",
    "padding  = 1\n",
    "\n",
    "# create the instance\n",
    "c = nn.Conv2d(inChans,outChans,krnSize,stride,padding)\n",
    "\n",
    "# create an image\n",
    "img = torch.rand(1,inChans,imsize[0],imsize[1])\n",
    "\n",
    "# run convolution and compute its shape\n",
    "resimg = c(img)\n",
    "empSize = torch.squeeze(resimg).shape\n",
    "\n",
    "# compute the size of the result according to the formula\n",
    "expectSize = np.array([outChans,0,0],dtype=int)\n",
    "expectSize[1] = np.floor( (imsize[0]+2*padding-krnSize)/stride[0] ) + 1\n",
    "expectSize[2] = np.floor( (imsize[1]+2*padding-krnSize)/stride[1] ) + 1\n",
    "\n",
    "# check the size of the output\n",
    "print(f'Expected size: {expectSize}')\n",
    "print(f'Empirical size: {list(empSize)}')"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Expected size: [  1 252  84]\n",
      "Empirical size: [252, 84]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCWyuNySDagy"
   },
   "source": [
    "# Real problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bteB_P10DSCM"
   },
   "source": [
    "### 1) Convolve an image of size 3x64x64 to produce a 10x28x28 result"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_8CM5aVADSCN"
   },
   "source": [
    "# parameters\n",
    "inChans  = \n",
    "imsize   = \n",
    "outChans = \n",
    "krnSize  = \n",
    "stride   = \n",
    "padding  = \n",
    "\n",
    "# create the instance\n",
    "c = nn.Conv2d(inChans,outChans,krnSize,stride,padding)\n",
    "\n",
    "# create an image\n",
    "img = torch.rand(1,inChans,imsize[0],imsize[1])\n",
    "\n",
    "# run convolution and compute its shape\n",
    "resimg = c(img)\n",
    "empSize = torch.squeeze(resimg).shape\n",
    "\n",
    "# compute the size of the result according to the formula\n",
    "expectSize = np.array([outChans,0,0],dtype=int)\n",
    "expectSize[1] = np.floor( (imsize[0]+2*padding-krnSize)/stride[0] ) + 1\n",
    "expectSize[2] = np.floor( (imsize[1]+2*padding-krnSize)/stride[1] ) + 1\n",
    "\n",
    "# check the size of the output\n",
    "print(f'Expected size: {expectSize}')\n",
    "print(f'Empirical size: {list(empSize)}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jfWAkiWDWU7"
   },
   "source": [
    "### 2) Convolve an image of size 3x196x96 to produce a 5x66x49 result"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XieXWJ9gDWU7"
   },
   "source": [
    "# parameters\n",
    "inChans  = \n",
    "imsize   = \n",
    "outChans = \n",
    "krnSize  = \n",
    "stride   = \n",
    "padding  = \n",
    "\n",
    "# create the instance\n",
    "c = nn.Conv2d(inChans,outChans,krnSize,stride,padding)\n",
    "\n",
    "# create an image\n",
    "img = torch.rand(1,inChans,imsize[0],imsize[1])\n",
    "\n",
    "# run convolution and compute its shape\n",
    "resimg = c(img)\n",
    "empSize = torch.squeeze(resimg).shape\n",
    "\n",
    "# compute the size of the result according to the formula\n",
    "expectSize = np.array([outChans,0,0],dtype=int)\n",
    "expectSize[1] = np.floor( (imsize[0]+2*padding-krnSize)/stride[0] ) + 1\n",
    "expectSize[2] = np.floor( (imsize[1]+2*padding-krnSize)/stride[1] ) + 1\n",
    "\n",
    "# check the size of the output\n",
    "print(f'Expected size: {expectSize}')\n",
    "print(f'Empirical size: {list(empSize)}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdRhRVE7FfN2"
   },
   "source": [
    "### 3) Convolve an image of size 1x32x32 to produce a 6x28x28 result"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "t5f9x7HjFfN2"
   },
   "source": [
    "# note: these dimensions are the input -> first hidden layer of the famous LeNet-5\n",
    "\n",
    "# parameters\n",
    "inChans  = \n",
    "imsize   = \n",
    "outChans = \n",
    "krnSize  = \n",
    "stride   = \n",
    "padding  = \n",
    "\n",
    "# create the instance\n",
    "c = nn.Conv2d(inChans,outChans,krnSize,stride,padding)\n",
    "\n",
    "# create an image\n",
    "img = torch.rand(1,inChans,imsize[0],imsize[1])\n",
    "\n",
    "# run convolution and compute its shape\n",
    "resimg = c(img)\n",
    "empSize = torch.squeeze(resimg).shape\n",
    "\n",
    "# compute the size of the result according to the formula\n",
    "expectSize = np.array([outChans,0,0],dtype=int)\n",
    "expectSize[1] = np.floor( (imsize[0]+2*padding-krnSize)/stride[0] ) + 1\n",
    "expectSize[2] = np.floor( (imsize[1]+2*padding-krnSize)/stride[1] ) + 1\n",
    "\n",
    "# check the size of the output\n",
    "print(f'Expected size: {expectSize}')\n",
    "print(f'Empirical size: {list(empSize)}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vrHM60CkF2pl"
   },
   "source": [
    "### 4) Convolve an image of size 3x227x227 to produce a 96x55x55 result"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "d0R0DITNF2pl"
   },
   "source": [
    "# note: these dimensions are the input -> first hidden layer of the famous AlexNet\n",
    "\n",
    "# parameters\n",
    "inChans  = \n",
    "imsize   = \n",
    "outChans = \n",
    "krnSize  = \n",
    "stride   = \n",
    "padding  = \n",
    "\n",
    "# create the instance\n",
    "c = nn.Conv2d(inChans,outChans,krnSize,stride,padding)\n",
    "\n",
    "# create an image\n",
    "img = torch.rand(1,inChans,imsize[0],imsize[1])\n",
    "\n",
    "# run convolution and compute its shape\n",
    "resimg = c(img)\n",
    "empSize = torch.squeeze(resimg).shape\n",
    "\n",
    "# compute the size of the result according to the formula\n",
    "expectSize = np.array([outChans,0,0],dtype=int)\n",
    "expectSize[1] = np.floor( (imsize[0]+2*padding-krnSize)/stride[0] ) + 1\n",
    "expectSize[2] = np.floor( (imsize[1]+2*padding-krnSize)/stride[1] ) + 1\n",
    "\n",
    "# check the size of the output\n",
    "print(f'Expected size: {expectSize}')\n",
    "print(f'Empirical size: {list(empSize)}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cvoJ9X5IHtl5"
   },
   "source": [
    "### 5) Convolve an image of size 3x224x224 to produce a 64x224x224 result"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PG4InNjQHtl6"
   },
   "source": [
    "# note: these dimensions are the input -> first hidden layer of the famous VGG-16\n",
    "\n",
    "# parameters\n",
    "inChans  = \n",
    "imsize   = \n",
    "outChans = \n",
    "krnSize  = \n",
    "stride   = \n",
    "padding  = \n",
    "\n",
    "# create the instance\n",
    "c = nn.Conv2d(inChans,outChans,krnSize,stride,padding)\n",
    "\n",
    "# create an image\n",
    "img = torch.rand(1,inChans,imsize[0],imsize[1])\n",
    "\n",
    "# run convolution and compute its shape\n",
    "resimg = c(img)\n",
    "empSize = torch.squeeze(resimg).shape\n",
    "\n",
    "# compute the size of the result according to the formula\n",
    "expectSize = np.array([outChans,0,0],dtype=int)\n",
    "expectSize[1] = np.floor( (imsize[0]+2*padding-krnSize)/stride[0] ) + 1\n",
    "expectSize[2] = np.floor( (imsize[1]+2*padding-krnSize)/stride[1] ) + 1\n",
    "\n",
    "# check the size of the output\n",
    "print(f'Expected size: {expectSize}')\n",
    "print(f'Empirical size: {list(empSize)}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "C8zLORJxEpqY"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "e-P_8vOjIVeP"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NDmDF1pPIVgn"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lXW4RaOAIVi4"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MLsIIb--IVkv"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lzMISeuyIVmx"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xTTygSkjIVov"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pbnr43FxIVq_"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yn6a-vl4IVs6"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mb0fBtyfEpsj"
   },
   "source": [
    "# Answers (don't cheat!)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gwR_5NyFErcf"
   },
   "source": [
    "# 1)\n",
    "inChans  = 3\n",
    "imsize   = [64,64]\n",
    "outChans = 10\n",
    "krnSize  = 9\n",
    "stride   = (2,2)\n",
    "padding  = 0\n",
    "\n",
    "# 2)\n",
    "inChans  = 3\n",
    "imsize   = [196,96]\n",
    "outChans = 5\n",
    "krnSize  = 5\n",
    "stride   = (3,2)\n",
    "padding  = 3\n",
    "\n",
    "# 3)\n",
    "inChans  = 1\n",
    "imsize   = [32,32]\n",
    "outChans = 6\n",
    "krnSize  = 5\n",
    "stride   = (1,1)\n",
    "padding  = 0\n",
    "\n",
    "# 4)\n",
    "inChans  = 3\n",
    "imsize   = [227,227]\n",
    "outChans = 96\n",
    "krnSize  = 11\n",
    "stride   = (4,4)\n",
    "padding  = 1\n",
    "\n",
    "# 5)\n",
    "inChans  = 3\n",
    "imsize   = [224,224]\n",
    "outChans = 64\n",
    "krnSize  = 3\n",
    "stride   = (1,1)\n",
    "padding  = 1"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}