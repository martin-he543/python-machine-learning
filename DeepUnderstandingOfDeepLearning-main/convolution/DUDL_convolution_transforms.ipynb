{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "DUDL_convolution_transforms.ipynb",
   "provenance": [
    {
     "file_id": "1m0n2-UmB2tJiIDadlFkE6L5A4iZSqeBf",
     "timestamp": 1619459134813
    },
    {
     "file_id": "19G9gTeBlYPQ-s3VS_3K2bVFtKTP344j6",
     "timestamp": 1619444797767
    },
    {
     "file_id": "1FcEBC0NAESIlHQkv6_85R-XDUKGE8XbM",
     "timestamp": 1619155961717
    },
    {
     "file_id": "1qKgZ8kVcqNgwtBzHbWq5yJH_HqI6DxWW",
     "timestamp": 1617803880910
    },
    {
     "file_id": "15cpyHkJ435B4MqbyGjAH1poN4nCy_DE4",
     "timestamp": 1617737766196
    },
    {
     "file_id": "1OLuWuaFu0hcFgkQ2hh5BqbRuqUZD7XcQ",
     "timestamp": 1617734878578
    },
    {
     "file_id": "1XvzVGJPTJifVh8OpZVB7ykLxyUqYwQ1j",
     "timestamp": 1617196833019
    },
    {
     "file_id": "1bv1_y32e3KEExFKKlPfC3rpw1JxmBr8H",
     "timestamp": 1617124341706
    },
    {
     "file_id": "1GMq8u7KyHB2AE7Teyls9gK1T01OduQSn",
     "timestamp": 1616697516760
    },
    {
     "file_id": "1Ui3kyHim-e0XLgDs2mkBxVlYg7TKYtcg",
     "timestamp": 1616615469755
    },
    {
     "file_id": "1YpHocGI4rApOxIBb1ZghCU5L-hFnv4CK",
     "timestamp": 1616608248670
    }
   ],
   "collapsed_sections": [],
   "authorship_tag": "ABX9TyNzAXVK67MmJWX6LzPABwTY"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhWV8oes-wKR"
   },
   "source": [
    "# COURSE: A deep understanding of deep learning\n",
    "## SECTION: Convolution and transformations\n",
    "### LECTURE: Image transformations\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com\n",
    "##### COURSE URL: udemy.com/course/deeplearning_x/?couponCode=202401"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YeuAheYyhdZw"
   },
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import torch \n",
    "\n",
    "# NEW!\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HOkOefftqyg"
   },
   "source": [
    "# Import a dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VhIKo0_iaGz2"
   },
   "source": [
    "# The list of datasets that come with torchvision: https://pytorch.org/vision/stable/index.html"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MU7rvmWuhjud"
   },
   "source": [
    "# download the CIFAR10 dataset\n",
    "cdata = torchvision.datasets.CIFAR10(root='cifar10', download=True)\n",
    "\n",
    "print(cdata)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NhN7RYqYd915"
   },
   "source": [
    "# check out the shape of the dataset\n",
    "print( cdata.data.shape )\n",
    "\n",
    "# the unique categories\n",
    "print( cdata.classes )\n",
    "\n",
    "# .targets is a list of targets converted to ints\n",
    "print( len(cdata.targets) )"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hMpyFzF-d95B"
   },
   "source": [
    "# inspect a few random images\n",
    "\n",
    "fig,axs = plt.subplots(5,5,figsize=(10,10))\n",
    "\n",
    "for ax in axs.flatten():\n",
    "\n",
    "  # select a random picture\n",
    "  randidx = np.random.choice(len(cdata.targets))\n",
    "\n",
    "  # extract that image\n",
    "  pic = cdata.data[randidx,:,:,:]\n",
    "  # and its label\n",
    "  label = cdata.classes[cdata.targets[randidx]]\n",
    "\n",
    "  # and show!\n",
    "  ax.imshow(pic)\n",
    "  ax.text(16,0,label,ha='center',fontweight='bold',color='k',backgroundcolor='y')\n",
    "  ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VAqVrcrGd98S"
   },
   "source": [
    "# Apply some transformations"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9SnUUHPm7xQE"
   },
   "source": [
    "Ts = T.Compose([ T.ToTensor(),\n",
    "                 T.Resize(32*4),\n",
    "                 T.Grayscale(num_output_channels=1)  ])\n",
    "\n",
    "# include the transform in the dataset\n",
    "cdata.transform = Ts\n",
    "\n",
    "# you can also apply the transforms immediately when loading in the data\n",
    "# cdata = torchvision.datasets.CIFAR10(root='cifar10', download=True, transform=Ts)\n",
    "\n",
    "\n",
    "# Important! Adding a transform doesn't change the image data:\n",
    "print(cdata.data[123,:,:,:].shape)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "poDa9N6TwjPu"
   },
   "source": [
    "# apply the transform\n",
    "\n",
    "# option 1a: apply the transform \"externally\" to an image\n",
    "img1 = Ts( cdata.data[123,:,:,:] )\n",
    "\n",
    "# option 1b: use the embedded transform\n",
    "img2 = cdata.transform( cdata.data[123,:,:,:] )\n",
    "\n",
    "# let's see what we've done!\n",
    "fig,ax = plt.subplots(1,3,figsize=(10,3))\n",
    "ax[0].imshow(cdata.data[123,:,:,:])\n",
    "ax[1].imshow(torch.squeeze(img1))\n",
    "ax[2].imshow(torch.squeeze(img2),cmap='gray')\n",
    "\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ze3BK_VJgBqd"
   },
   "source": [
    "# Note about ToTensor() and normalization:\n",
    "??T.ToTensor()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fCooGt9PiNb6"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVXQlW-svDUE"
   },
   "source": [
    "# Additional explorations"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nViqoQuOvbZB"
   },
   "source": [
    "# 1) There are many other transforms available in torchvision: https://pytorch.org/vision/stable/transforms.html\n",
    "#    Many transformations are useful for data preparation and augmentation. We'll cover some of them later in the course,\n",
    "#    but for now, read about RandomCrop(), RandomHorizontalFlip(), and CenterCrop(). Then implement them to understand \n",
    "#    what they do to images.\n",
    "#    Tip: It's probably best to test these transforms separately, and on one test image, as we did above.\n",
    "# "
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}